<?xml version="1.0" encoding="UTF-8"?>

<!--

  ~ Copyright 2001, 2012, Oracle and/or its affiliates. All rights reserved.

  ~ Oracle and Java are registered trademarks of Oracle and/or its

  ~ affiliates. Other names may be trademarks of their respective owners.

  ~ UNIX is a registered trademark of The Open Group.

  ~

  ~ This software and related documentation are provided under a license

  ~ agreement containing restrictions on use and disclosure and are

  ~ protected by intellectual property laws. Except as expressly permitted

  ~ in your license agreement or allowed by law, you may not use, copy,

  ~ reproduce, translate, broadcast, modify, license, transmit, distribute,

  ~ exhibit, perform, publish, or display any part, in any form, or by any

  ~ means. Reverse engineering, disassembly, or decompilation of this

  ~ software, unless required by law for interoperability, is prohibited.

  ~ The information contained herein is subject to change without notice

  ~ and is not warranted to be error-free. If you find any errors, please

  ~ report them to us in writing.

  ~ U.S. GOVERNMENT END USERS: Oracle programs, including any operating

  ~ system, integrated software, any programs installed on the hardware,

  ~ and/or documentation, delivered to U.S. Government end users are

  ~ "commercial computer software" pursuant to the applicable Federal

  ~ Acquisition Regulation and agency-specific supplemental regulations.

  ~ As such, use, duplication, disclosure, modification, and adaptation

  ~ of the programs, including any operating system, integrated software,

  ~ any programs installed on the hardware, and/or documentation, shall be

  ~ subject to license terms and license restrictions applicable to the

  ~ programs. No other rights are granted to the U.S. Government.

  ~ This software or hardware is developed for general use in a variety

  ~ of information management applications. It is not developed or

  ~ intended for use in any inherently dangerous applications, including

  ~ applications that may create a risk of personal injury. If you use

  ~ this software or hardware in dangerous applications, then you shall

  ~ be responsible to take all appropriate fail-safe, backup, redundancy,

  ~ and other measures to ensure its safe use. Oracle Corporation and its

  ~ affiliates disclaim any liability for any damages caused by use of this

  ~ software or hardware in dangerous applications.

  ~ This software or hardware and documentation may provide access to or

  ~ information on content, products, and services from third parties.

  ~ Oracle Corporation and its affiliates are not responsible for and

  ~ expressly disclaim all warranties of any kind with respect to

  ~ third-party content, products, and services. Oracle Corporation and

  ~ its affiliates will not be responsible for any loss, costs, or damages

  ~ incurred due to your access to or use of third-party content, products,

  ~ or services.

  -->



<spr:beans xmlns:spr="http://www.springframework.org/schema/beans"

  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"

  xmlns:tx="http://www.springframework.org/schema/tx"

  xmlns:aop="http://www.springframework.org/schema/aop"

  xmlns="http://www.endeca.com/schema/eacToolkit"

  xsi:schemaLocation="

      http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd

      http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd

      http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd

      http://www.endeca.com/schema/eacToolkit http://www.endeca.com/schema/eacToolkit/eacToolkit.xsd">



  <!--

    ########################################################################

    # Data Ingest Hosts

    #

  -->

  <host id="ITLHost" hostName="@@HOST@@" port="@@EAC_PORT@@" />



  <!--

    ########################################################################

    # Baseline Update Script

    #

  -->

  <script id="BaselineUpdate">

    <log-dir>./logs/provisioned_scripts</log-dir>

    <provisioned-script-command>./control/baseline_update.@@SCRIPT_SUFFIX@@</provisioned-script-command>

    <bean-shell-script>

      <![CDATA[ 

    log.info("Starting baseline update script.");

    // obtain lock

    if (LockManager.acquireLock("update_lock")) {



        // clean directories

        Forge.cleanDirs();

        PartialForge.cleanCumulativePartials();

        Dgidx.cleanDirs();

        

        // fetch extracted data files to forge input

        Forge.getIncomingData();

        

        // fetch config files to forge input

        Forge.getConfig();



        // Generate instance configuration

        ConfigurationGeneratorForge.archiveLogDir();

        ConfigurationGeneratorForge.run();
        
        CopyRecsearchConfig.run();



        // archive logs and run ITL

        Forge.archiveLogDir();

        Forge.run();

        Dgidx.archiveLogDir();

        Dgidx.run();

        

        // distributed index, update Dgraphs

        DistributeIndexAndApply.run();



        // Upload the generated dimension values to Workbench

        WorkbenchManager.cleanDirs();

        Forge.getPostForgeDimensions();

        WorkbenchManager.updateWsDimensions();



        // Upload the generated config to Workbench

        WorkbenchManager.updateWsConfig();

        

        // archive state files, index

        Forge.archiveState();

        Dgidx.archiveIndex();

        

        // (start or) cycle the LogServer

        LogServer.cycle();  



        // release lock

        LockManager.releaseLock("update_lock");

        log.info("Baseline update script finished.");

    } else {

      log.warning("Failed to obtain lock.");

    }

      ]]>

    </bean-shell-script>

  </script>





  <!--

    ########################################################################

    # Script to distribute index to dgraph servers, then update dgraphs

    # with the distributed index. This script can be called to update or

    # refresh the index of the dgraph cluster in case a server fails, a

    # new dgraph is added, or the index simply needs to be updated.

    #

  -->

  <script id="DistributeIndexAndApply">

    <bean-shell-script>

      <![CDATA[ 

    AuthoringDgraphCluster.cleanDirs();

    AuthoringDgraphCluster.copyIndexToDgraphServers();

    AuthoringDgraphCluster.applyIndex();



    LiveDgraphCluster.cleanDirs();

    LiveDgraphCluster.copyIndexToDgraphServers();

    LiveDgraphCluster.applyIndex();

      ]]>

    </bean-shell-script>

  </script>





  <!--

    ########################################################################

    # Partial Update Script

    #

  -->

  <script id="PartialUpdate">

    <log-dir>./logs/provisioned_scripts</log-dir>

    <provisioned-script-command>./control/partial_update.@@SCRIPT_SUFFIX@@</provisioned-script-command>

    <bean-shell-script>

      <![CDATA[ 

 

    log.info("Starting partial update script.");

    // get current read generation ID for the FORGE client

    // to be used in the event of a failure

    rsClient = new com.endeca.itl.recordstore.client.ReadGenerationClient("${CAS_HOST}",${CAS_PORT},"${ENDECA_PROJECT_NAME}_${LANGUAGE_ID}_data");

    id = rsClient.getReadGenerationByClientId("${CAS_CLIENT_ID}");

    if (id == 0) {

        throw new Exception("No data has been previously read from record store ${ENDECA_PROJECT_NAME}_${LANGUAGE_ID}_data. " + 

            "A baseline update must be run before a partial update can be run.");

    }



    try {

        // obtain lock

        if (LockManager.acquireLock("update_lock")) {

            // archive logs

            PartialForge.archiveLogDir();

            

            // clean directories

            PartialForge.cleanDirs();

            

            // fetch extracted data files to forge input

            PartialForge.getPartialIncomingData();

            

            // fetch config files to forge input

            PartialForge.getConfig();

            

            // run ITL

            PartialForge.run();

            

            // timestamp partial, save to cumulative partials dir

            PartialForge.timestampPartials();

            PartialForge.fetchPartialsToCumulativeDir();

            

            // distribute partial update, update Dgraphs

            AuthoringDgraphCluster.copyPartialUpdateToDgraphServers();

            AuthoringDgraphCluster.applyPartialUpdates();



            LiveDgraphCluster.copyPartialUpdateToDgraphServers();

            LiveDgraphCluster.applyPartialUpdates();

            

            // archive partials

            PartialForge.archiveCumulativePartials();

            // release lock

            LockManager.releaseLock("update_lock");

            log.info("Partial update script finished.");

        } else {

            log.warning("Failed to obtain lock.");

        }

      } catch (e) {

        log.severe("Exception occurred: " + e);

        rsClient.setReadGenerationByClientId("${CAS_CLIENT_ID}", id);

        log.info("Rolling back read generation id to: " + id);

        id = rsClient.getReadGenerationByClientId("${CAS_CLIENT_ID}");

        log.info("Verify new read generation id is: "+id);

        throw e;

      }

 

      ]]>

    </bean-shell-script>

  </script>





  <!--

    ########################################################################

    # Script to distribute cumulative partials to dgraph servers, then 

    # update dgraphs with the distributed partials. This script can be 

    # called to update or refresh the state of the dgraph cluster in case a 

    # server fails, a new dgraph is added, or the index simply needs to be 

    # updated. If a refresh is required between baselines, this script will

    # distribute all partial updates that represent the changes to the index

    # since the last baseline.

    #

  -->

  <script id="DistributePartialsAndApply">

    <bean-shell-script>

      <![CDATA[ 

    AuthoringDgraphCluster.cleanLocalPartialsDirs();

    AuthoringDgraphCluster.copyCumulativePartialUpdatesToDgraphServers();

    AuthoringDgraphCluster.applyPartialUpdates();



    LiveDgraphCluster.cleanLocalPartialsDirs();

    LiveDgraphCluster.copyCumulativePartialUpdatesToDgraphServers();

    LiveDgraphCluster.applyPartialUpdates();

      ]]>

    </bean-shell-script>

  </script>

  

  <!--

    ########################################################################

    # Script to fetch merged instance configuration and initiate instance

    # configuration generation. Useful for testing the output of the

    # Forge Configuration Manager without running a full baseline.

    #

  -->

  <script id="TestConfigurationGenerationForge">

    <bean-shell-script>

      <![CDATA[

      Forge.cleanDirs();

      Forge.getIncomingData();

      Forge.getConfig();

      ConfigurationGeneratorForge.archiveLogDir();

      log.info("Beginning configuration generation.");

      ConfigurationGeneratorForge.run();

      log.info("Configuration generation complete.");

      ]]>

    </bean-shell-script>

  </script>



  <!--

    ########################################################################

    # Configuration Generator Forge

    #

  -->

  <forge id="ConfigurationGeneratorForge" host-id="ITLHost">

    <properties>

      <property name="numLogBackups" value="1" />

    </properties>

    <args>

      <arg>-vi</arg>

      <arg>--javaClasspath</arg>

      <arg>${FORGE_FCM_CLASSPATH}</arg>

      <arg>--javaArgument</arg>

      <arg>-DENDECA_PROJECT_NAME=${ENDECA_PROJECT_NAME}</arg>

      <arg>--javaArgument</arg>

      <arg>-Dendeca.project.dir=${ENDECA_PROJECT_DIR}</arg>

      <arg>--javaArgument</arg>

      <arg>-Xmx1024m</arg>

      <arg>--javaArgument</arg>

      <arg>-Djava.util.logging.config.file=./config/script/logging.properties</arg>

    </args>

    <log-dir>./logs/forges/ConfigurationGeneratorForge</log-dir>

    <input-dir>./data/processing</input-dir>

    <output-dir>./data/processing</output-dir>

    <temp-dir>./data/temp</temp-dir>

    <pipeline-file>./config/pipeline/configurationGenerator.epx</pipeline-file>

  </forge>

  

  <!--

    ########################################################################

    # Forge

    #

  -->

  <forge id="Forge" host-id="ITLHost">

    <properties>

      <property name="numStateBackups" value="10" />

      <property name="numLogBackups" value="10" />

    </properties>

    <directories>

      <directory name="incomingDataDir">./data/incoming</directory>

      <directory name="configDir">./config/pipeline</directory>

      <directory name="wsTempDir">./data/workbench/temp</directory>

    </directories>

    <args>

      <arg>-vw</arg>

      <arg>--javaClasspath</arg>

      <arg>${FORGE_CLASSPATH}</arg>

      <arg>--javaArgument</arg>

      <arg>-DENDECA_PROJECT_NAME=${ENDECA_PROJECT_NAME}</arg>

      <arg>--javaArgument</arg>

      <arg>-Djava.util.logging.config.file=./config/script/logging.properties</arg>

    </args>

    <log-dir>./logs/forges/Forge</log-dir>

    <input-dir>./data/processing</input-dir>

    <output-dir>./data/forge_output</output-dir>

    <state-dir>./data/state</state-dir>

    <temp-dir>./data/temp</temp-dir>

    <num-partitions>1</num-partitions>

    <pipeline-file>./data/processing/pipeline.epx</pipeline-file>

  </forge>



  <!--

    ########################################################################

    # Partial Update Forge

    #

  -->

  <forge id="PartialForge" host-id="ITLHost">

    <properties>

      <property name="numLogBackups" value="10" />

      <property name="numPartialsBackups" value="5" />

    </properties>

    <directories>

      <directory name="incomingDataDir">./data/partials/incoming</directory>

      <!-- point PartialForge to the directory with FCM modified config -->

      <directory name="configDir">./data/processing</directory>

      <directory name="cumulativePartialsDir">./data/partials/cumulative_partials</directory>

    </directories>

    <args>

      <arg>-vw</arg>

      <arg>--javaClasspath</arg>

      <arg>${FORGE_CLASSPATH}</arg>

      <arg>--javaArgument</arg>

      <arg>-DENDECA_PROJECT_NAME=${ENDECA_PROJECT_NAME}</arg>

      <arg>--javaArgument</arg>

      <arg>-Djava.util.logging.config.file=./config/script/logging.properties</arg>

    </args>

    <log-dir>./logs/forges/PartialForge</log-dir>

    <input-dir>./data/partials/processing</input-dir>

    <output-dir>./data/partials/forge_output</output-dir>

    <state-dir>./data/state</state-dir>

    <temp-dir>./data/temp</temp-dir>

    <num-partitions>1</num-partitions>

    <pipeline-file>./data/partials/processing/partial_pipeline.epx</pipeline-file>

  </forge>



  <!--

    ########################################################################

    # Dgidx

    #

  -->

  <dgidx id="Dgidx" host-id="ITLHost">

    <properties>

      <property name="numLogBackups" value="10" />

      <property name="numIndexBackups" value="3" />

    </properties>

    <args>

      <arg>-v</arg>

      <arg>--compoundDimSearch</arg>

      <arg>--lang</arg>

      <arg>${LANGUAGE_ID}</arg>

    </args>

    <log-dir>./logs/dgidxs/Dgidx</log-dir>

    <input-dir>./data/forge_output</input-dir>

    <output-dir>./data/dgidx_output</output-dir>

    <temp-dir>./data/temp</temp-dir>

    <run-aspell>true</run-aspell>

  </dgidx>

  <!--
    ########################################################################
    # Copy recsearch_config.xml
    #
  -->
  <copy id="CopyRecsearchConfig" src-host-id="ITLHost" dest-host-id="ITLHost" recursive="true">
   
    <src>./config/pipeline/${ENDECA_PROJECT_NAME}.recsearch_config.xml</src>
    
    <dest>./data/processing/${ENDECA_PROJECT_NAME}.recsearch_config.xml</dest>
  
  </copy>


</spr:beans>
<!-- @version $Id: //hosting-blueprint/B2CBlueprint/version/10.2/Storefront/deploy/script/DataIngest.xml#2 $$Change: 768606 $-->
